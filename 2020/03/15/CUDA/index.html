<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>Gavin-CUDA学习记录 | Blog</title>

  <!-- keywords -->
  
    <meta name="keywords" content="Gavin">
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="CUDA Learning Record随着显卡的发展,GPU越来越强大,在计算上已经超过了通用的CPU.为了更大限度的利用GPU的运算能力,NVIDIA推出CUDA, 使得显卡可以用与图像计算之外的目的. CPU+GPU异构并行计算架构CPU与GPU是两个独立的处理器，之间通过PCIe总线相连。GPU不是一个独立的运行平台，而是CPU的一个协处理器。CPU所在位置称为主机端(host)，GPU所">
<meta name="keywords" content="HPC">
<meta property="og:type" content="article">
<meta property="og:title" content="CUDA学习记录">
<meta property="og:url" content="http://yoursite.com/2020/03/15/CUDA/index.html">
<meta property="og:site_name" content="Blog">
<meta property="og:description" content="CUDA Learning Record随着显卡的发展,GPU越来越强大,在计算上已经超过了通用的CPU.为了更大限度的利用GPU的运算能力,NVIDIA推出CUDA, 使得显卡可以用与图像计算之外的目的. CPU+GPU异构并行计算架构CPU与GPU是两个独立的处理器，之间通过PCIe总线相连。GPU不是一个独立的运行平台，而是CPU的一个协处理器。CPU所在位置称为主机端(host)，GPU所">
<meta property="og:locale" content="English & Chinese">
<meta property="og:image" content="http://yoursite.com/Pictures/nvcc编译过程.png">
<meta property="og:image" content="http://yoursite.com/Pictures/线程分配.png">
<meta property="og:image" content="http://yoursite.com/Pictures/内存类型.png">
<meta property="og:updated_time" content="2020-09-30T04:43:41.288Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CUDA学习记录">
<meta name="twitter:description" content="CUDA Learning Record随着显卡的发展,GPU越来越强大,在计算上已经超过了通用的CPU.为了更大限度的利用GPU的运算能力,NVIDIA推出CUDA, 使得显卡可以用与图像计算之外的目的. CPU+GPU异构并行计算架构CPU与GPU是两个独立的处理器，之间通过PCIe总线相连。GPU不是一个独立的运行平台，而是CPU的一个协处理器。CPU所在位置称为主机端(host)，GPU所">
<meta name="twitter:image" content="http://yoursite.com/Pictures/nvcc编译过程.png">
  
    <link rel="alternative" href="/atom.xml" title="Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/Pictures/timg.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  
<script>
    (function(){
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
        }
        else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

  
<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-85415703-1', 'auto');
  ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


  <script src="//cdn.bootcss.com/require.js/2.3.2/require.min.js"></script>
  <script src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script>

  
      <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
<script>AV.initialize("your_app_id", "your_app_key");</script>
<script src="/js/Counter.js"></script>
  
</head></html>
<body>
  <div id="container">
    <div id="particles-js"></div>
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="/Pictures/timg.ico" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Weizhe Yang</a></h1>
		</hgroup>

		
		<p class="header-subtitle">Weizhe</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="2">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						<li>友情链接</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/GavinWz/" title="github">github</a>
					        
								<a class="mail" target="_blank" href="/gavinwzmails@gmail.com" title="mail">mail</a>
					        
								<a class="qq" target="_blank" href="#" title="qq">qq</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/HPC/" style="font-size: 20px;">HPC</a> <a href="/tags/hexo/" style="font-size: 10px;">hexo</a> <a href="/tags/学习记录/" style="font-size: 15px;">学习记录</a>
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://www.iczc.me/">iczc</a>
			        
			        </div>
				</section>
				

				
				
				<section class="switch-part switch-part4">
				
					<div id="js-aboutme">A student of the College of Computer Engineering of Weifang University. I&#39;m learning hard on Information Technology, and this is where I save my study records.Not all the essays here are my original works, but some of them have helped me a lot in the past time, so I recorded them to share with everyone and it also remind me what should I do if I face the same situations which I have met in the past but forgot how to operate now.</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Weizhe Yang</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="/Pictures/timg.ico" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author">Weizhe Yang</h1>
			</hgroup>
			
			<p class="header-subtitle">Weizhe</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/GavinWz/" title="github">github</a>
			        
						<a class="mail" target="_blank" href="/gavinwzmails@gmail.com" title="mail">mail</a>
			        
						<a class="qq" target="_blank" href="#" title="qq">qq</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-CUDA" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/03/15/CUDA/" class="article-date">
  	<time datetime="2020-03-15T08:05:02.000Z" itemprop="datePublished">2020-03-15</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      CUDA学习记录
      
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HPC/">HPC</a></li></ul>
	</div>

        

        
          
<div class="counter-tag counter">
    <span id="/2020/03/15/CUDA/" class="leancloud_visitors post-title-link" style="font-size: 12px" data-flag-title="CUDA学习记录">
         &nbsp;
        view
    </span>
</div>

        
        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="CUDA-Learning-Record"><a href="#CUDA-Learning-Record" class="headerlink" title="CUDA Learning Record"></a>CUDA Learning Record</h2><p>随着显卡的发展,GPU越来越强大,在计算上已经超过了通用的CPU.为了更大限度的利用GPU的运算能力,NVIDIA推出CUDA, 使得显卡可以用与图像计算之外的目的.</p>
<h3 id="CPU-GPU异构并行计算架构"><a href="#CPU-GPU异构并行计算架构" class="headerlink" title="CPU+GPU异构并行计算架构"></a>CPU+GPU异构并行计算架构</h3><p>CPU与GPU是两个独立的处理器，之间通过PCIe总线相连。GPU不是一个独立的运行平台，而是CPU的一个协处理器。CPU所在位置称为主机端(host)，GPU所在位置称为设备端(device)</p>
<ol>
<li>评价GPU的指标<br>描述GPU容量的两个重要特征：</li>
</ol>
<ul>
<li>CUDA核心数量</li>
<li>内存大小</li>
</ul>
<p>相应的，评价GPU性能的两种指标：</p>
<ul>
<li>峰值计算性能</li>
<li>显存带宽</li>
</ul>
<p>峰值计算性能用来评估计算容量，通常定义为每秒能够处理的单精度或双精度浮点运算的数量。单位通常为GFlops(每秒十亿次运算)或TFlops(每秒万亿次运算)。<br>显存带宽是从内存中读取或写入数据的比率。单位通常为GB/s。</p>
<ol start="2">
<li>CPU与GPU的线程与核心</li>
</ol>
<p>CPU的线程通常是重量级的实体，操作系统必须交替线程，启用或关闭CPU执行通道，以提供多线程处理功能，上下文切换缓慢且开销大。</p>
<p>GPU的线程是高度轻量级的，在一个典型的系统中会有成千上万的线程排队等待工作。</p>
<p>CPU的核心被设计为尽可能减少一个或两个线程运行时间的延迟</p>
<p>GPU的核心是用来处理大量并发的、轻量级的线程，以最大限度地提高吞吐量</p>
<ol start="3">
<li>CPU+GPU异构</li>
</ol>
<p>CPU具有处理复杂逻辑和指令级并行的能力   </p>
<p>GPU中有大量可编程核心，可支持大规模多线程运算，且相比CPU有更大的峰值带宽。   </p>
<p>CPU+GPU的异构并行计算架构利用CPU和GPU的功能互补性，使得程序能够获得最佳的运行效果。<br>在CPU上执行串行部分或任务并行部分，在GPU上执行数据密集型并行部分。</p>
<h3 id="CUDA编程模型"><a href="#CUDA编程模型" class="headerlink" title="CUDA编程模型"></a>CUDA编程模型</h3><p>程序中用host指代CPU及其内存, 用device指代GPU及其内存.CUDA程序中既包含host程序又包含device程序,他们分别在CPU和GPU上运行. 同时,host与device之间可以进行通信.</p>
<ol>
<li>nvcc的编译过程</li>
</ol>
<p><img src="/Pictures/nvcc编译过程.png" alt="nvcc编译过程"></p>
<p>CUDA的编译器驱动nvcc先将全部源代码分离为主机(host)代码和设备(device)代码。主机代码完全支持C++语法，而设备代码只是部分支持。</p>
<p>nvcc先将设备代码编译为PTX(Parallel Thread eXecution)伪汇编代码，再将PTX代码编译为二进制的cubin目标代码</p>
<ol start="2">
<li>nvcc编译选项</li>
</ol>
<ul>
<li><p>在将源代码编译为PTX代码时，需要用选项<code>-arch=copute_XY</code>指定一个虚拟架构的计算能力，以确定代码中能够使用的CUDA功能。</p>
</li>
<li><p>在将PTX代码编译为cubin代码时，需要用选项<code>-code=sm_ZW</code>指定一个真实架构的计算能力，以确定可执行文件能使用的GPU。指定了GPU的真实架构为Z.W,对应的可执行文件只能在主版本号为Z、次版本号大于等于W的GPU中运行。</p>
</li>
<li><p>真实架构的计算能力必须大于虚拟架构的计算能力</p>
</li>
<li><p>使得编译出来的可执行文件在更多的GPU中执行，可以同时指定多组计算能力，每一组用如下形式的编译选项：<br><code>gencode arch=compute_XY,code=sm_ZW</code></p>
</li>
<li><p>即时编译：在运行可执行文件时，从其中保留的PTX代码中临时编译出一个cubin目标代码，编译时保留这样的PTX代码需要用如下编译选项指定虚拟架构：<br><code>-gencode arch=compute_XY,code=compute_XY</code></p>
</li>
<li><p><code>arch=sm_XY</code>等价于</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-gencode arch=compute_XY,code=sm_XY</span><br><span class="line">-gencode arch=compute_XY,code=compute_XY</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ol start="3">
<li>CUDA程序的基本框架</li>
</ol>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">头文件包含</span><br><span class="line">宏定义</span><br><span class="line">用户函数和CUDA核函数的声明</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    分配主机与设备内存</span><br><span class="line">    初始化主机中的数据</span><br><span class="line">    将某些数据从主机复制到设备</span><br><span class="line">    调用核函数在设备中进行计算</span><br><span class="line">    将某些数据从设备复制到机</span><br><span class="line">    释放主机与设备内存</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="CUDA-C语法"><a href="#CUDA-C语法" class="headerlink" title="CUDA C语法"></a>CUDA C语法</h3><p><img src="/Pictures/线程分配.png" alt="线程分配"></p>
<ul>
<li>核函数中的线程常组织为若干个线程块(thread block)，每个线程块中有若干个线程(thread)。</li>
<li>核函数中的全部线程块构成一个网格(grid)，线程块的个数记为网格大小(grid size)，每个线程块中有同样数目的线程，该数目称为线程块大小(block size)。</li>
</ul>
<ol>
<li>__global__</li>
</ol>
<p><strong>global</strong>是CUDA C/C++的函数修饰符, 表示该函数为一个kernel函数, 该函数在CPU上调用，且:</p>
<ul>
<li>该函数会在GPU(device)上执行</li>
<li>必须返回void</li>
<li>由主机(host)代码调用:<br><code>fun_name&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;()</code></li>
<li>在调用kernel函数时,函数名后的&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;<ul>
<li>gird_size表示网格大小</li>
<li>block_size表示线程块大小</li>
</ul>
</li>
</ul>
<ol start="2">
<li>线程索引<br>在核函数内部，程序将配置参数gird_size和block_size这两个参数值分别保存于如下两个内建变量(built-in variable)中：</li>
</ol>
<ul>
<li>gridDim.x: 数值于grid_size相等</li>
<li>blockDim.x: 数值与block_size相等<br>类似地，在核函数中预定义了如下表示线程的内建变量：</li>
<li>blockIdx.x: 指定一个线程在网格中的线程块指标，取值范围是从0到gridDim.x-1。</li>
<li>threadIdx.x: 指定一个线程在线程块中的线程指标，取值范围是从0到blockDim.x-1。</li>
</ul>
<ol start="3">
<li>多维网格</li>
</ol>
<ul>
<li>unit3：<br>  blockIdx和threadIdx是类型为unit3的结构体变量，该结构体共有三个成员变量x，y，z。</li>
<li>gridDim：<br>  gridDim和blockDim是类型为dim3的结构体变量，该结构体共有三个成员变量x，y，z。<br>这些内建变量均只在核函数中有效(可见)。在调用核函数时的执行配置中：  </li>
</ul>
<p><code>&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;</code>  </p>
<p>grid_size和block_size的值被分别赋给内建变量gridDim.x和blockDim.x，此时，girdDim和blockDim中没有被指定的成员y和z取默认值1。在这种情况下，网格和线程块均为“一维”的。</p>
<ul>
<li>构造多维网格和线程块：<br>因为gird_size和block_size均为dim3结构体类型，所以可以通过结构体dim3来定义多维的网格和线程块(用到了C++中构造函数的语法)：<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">dim3 <span class="title">grid_size</span><span class="params">(Gx ,Gy, Gz)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">block_size</span><span class="params">(Bx, By, Bz)</span></span>;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>表示一维时，y和z可省略<br>表示二维时，z可省略</p>
<p>多维线程块本质上还是一维的，与多维线程指标threadId.x, threadIdy, threadId.z对应的一维线程指标为：  </p>
<p><code>tid = threadId.x * blockDim.x + threadId.y * blockDim.y + threadId.z * blickDim.z;</code></p>
<p>与多维线程块指标blockIdx.x, blockIdx.y, blockIdx.z相关联的线程块指标为：</p>
<p><code>bid = blockIdx.z * girdDim.x * gridDim.y + blockIdx.y * gridDim.x + blockIdx.x;</code></p>
<ul>
<li>网格与线程块大小的限制</li>
</ul>
<p>网格大小(grid_size)在x、y、z三个方向的最大允许值分别为2^31-1、65535、65535</p>
<p>线程块大小(thread_size)在x、y、z三个方向的最大允许值分别为1024、1024、64。且blockDim.x、 blockDim.y、blockDim.z的乘积不能大于1024，即无论如何分配，一个线程块最多只能有1024个线程。</p>
<ul>
<li>通常，一个网格会被组织成线程块的二维形式，一个线程块会被组织成线程的三维形式。</li>
</ul>
<ol start="4">
<li>函数执行空间标识符</li>
</ol>
<ul>
<li>用<strong>global</strong>修饰的函数叫做核函数，一般由主机调用，在设备执行。如果使用动态并行，则也可以在核函数中调用自己或其它核函数</li>
<li>用<strong>device</strong>修饰的函数叫做设备函数，只能被核函数或其它设备函数调用，并在设备中执行。</li>
<li>用<strong>host</strong>修饰的函数就是普通的C函数，在主机调用和执行。可以用<strong>host</strong>和<strong>device</strong>同时修饰一个函数，使得该函数既是一个主机函数，又是一个设备函数，以减少冗余代码。</li>
<li>不能同时用<strong>device</strong>和<strong>global</strong>修饰一个函数，即一个函数不能同时为设备函数和核函数</li>
<li>不能同时用<strong>host</strong>和<strong>global</strong>修饰一个函数，即一个函数不能同时为主机函数和核函数。</li>
<li>编译器把设备函数当做内联函数或非内联函数，可用修饰符<strong>noinline</strong>建议一个设备函数为非内联函数，也可以用修饰符<strong>forceinline</strong>建议一个设备函数为内联函数。</li>
</ul>
<ol start="5">
<li>设备内存的分类</li>
</ol>
<p><img src="/Pictures/内存类型.png" alt="设备内存分类"></p>
<p><strong>全局内存</strong></p>
<p>全局内存的含义是核函数中的所有线程都能够访问其中的数据。主要作用是为核函数提供数据，并在主机与设备以及设备与设备之间传输数据。<br>全局内存的生命周期不是由核函数决定的，而是由主机端决定的</p>
<p><strong>静态全局内存变量</strong></p>
<p>静态全局内存变量所占的内存数量是在编译期间就确定的，且必须在说有主机与设备函数外部定义。<br>对应的变量从其定义之处开始、一个翻译单元内的所有设备函数直接可见。</p>
<p>静态全局内存变量的定义：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">__device__ T x = <span class="number">0</span>; <span class="comment">//单个变量</span></span><br><span class="line">__device__ T y[N];  <span class="comment">//固定长度的数组</span></span><br></pre></td></tr></table></figure></p>
<p>T为变量类型。   </p>
<p>一般来说不建议使用静态全局内存变量</p>
<p><strong>常量内存</strong></p>
<p>常量内存是具有缓存的全局内存，一共仅有64KB，仅可读不可写。</p>
<p>在核函数外用<strong>constant</strong>定义常量内存，并用CUDA运行时API函数cudaMemcpyToSymbol将数据从主机端复制到设备的常量内存后供核函数使用。核函数对常量内存的访问要比对全局内存的访问要快。</p>
<p>计算能力大于等于2.0时，通过传值方式传给核函数的参数存放在常量内存中，该参数的内存在大于4KB，小于64KB时必须在定义时用<strong>constant</strong>修饰</p>
<p><strong>纹理内存和表面内存</strong></p>
<p>纹理内存和表面内存类似于常量内存，也是一种具有缓存的全局内存，而且一般仅可读(表面内存也可写)。但是纹理内存和表面内存的容量更大，且使用方式与常量内存不同。</p>
<p>对于算力大于等于3.5的GPU而言，将某些只读全局内存变量用<strong>__ldg()</strong>函数通过只读数据缓存读取，可以达到到使用纹理内存的加速效果。</p>
<p><code>T __ldg(const T *address)</code></p>
<p><strong>寄存器</strong></p>
<p>核函数中定义的不加任何限定符的变量一般来说存放在寄存器(register)中，但也可能存放于局部内存。</p>
<p>各种内建变量以及线程束大小(warpSize)都保存在特殊的寄存器中</p>
<p>寄存器变量仅仅被一个线程可见。</p>
<p><strong>局部内存</strong></p>
<p>寄存器中放不下的变量，以及索引值不能在编译时就确定的数组，有可能放在局部内存，由编译器自动决定。</p>
<p><strong>共享内存</strong></p>
<p>共享内存存在于芯片上，具有仅次于寄存器的读写速度。但它对于整个线程块可见，生命周期也与整个线程块一致。</p>
<p>共享内存的作用是减少对全局内存的访问。</p>
<ol start="6">
<li>检测运行时错误</li>
</ol>
<ul>
<li>CHECK函数<br>在头文件文件error.cuh中编写宏函数CHECK，输出捕获的运行时错误。<br>函数头为：<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CHECK(call) \</span></span><br><span class="line">...                 \</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>其中call为一个CUDA运行时API函数，调用时将一个CUDA运行时API函数作为参数传进该函数即可检验此运行时API函数在运行时发生的错误，并输出错误信息。</p>
<ul>
<li>检查核函数<br>捕捉调用核函数时可能发生的错误，需要在调用核函数之后加上如下两句：<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CHECK(cudaGetLastError());</span><br><span class="line">CHECK(cudaDeviceSynchronize());</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ol start="7">
<li><p>CUDA-MEMCHECK检查内存错误<br>CUDA-MEMCHECK工具集包括memcheck、rececheck、initcheck、synccheck四个工具。他们可由可执行文件cuda-memcheck调用：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cuda-memcheck --tool memcheck [options] app_name [options]</span><br><span class="line">cuda-memcheck --tool racecheck [options] app_name [options]</span><br><span class="line">cuda-memcheck --tool initcheck [options] app_name [options]</span><br><span class="line">cuda-memcheck --tool synccheck [options] app_name [options]</span><br></pre></td></tr></table></figure>
</li>
<li><p>用CUDA事件计时</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cudaEvent_t start, stop;</span><br><span class="line">cudaEventCreate(&amp;start); <span class="comment">//创建事件类型变量</span></span><br><span class="line">cudaEventCreate(&amp;stop);</span><br><span class="line">cudaEventRecord(start); <span class="comment">//记录事件的开始</span></span><br><span class="line">cudaEventQuery(start);  <span class="comment">//查询Record是否完成事件的捕获</span></span><br><span class="line"></span><br><span class="line">operate_fun(...);</span><br><span class="line"></span><br><span class="line">cudaEventRecord(stop);  <span class="comment">//记录事件的结束</span></span><br><span class="line">cudaEventSynchronize(stop); <span class="comment">//等待记录完成</span></span><br><span class="line"><span class="keyword">float</span> elapsed_time;</span><br><span class="line">cudaEventElapsedTime(&amp;elapsed_time, start, stop);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Time = %f ms.\n"</span>, elapsed_time);</span><br><span class="line">cudaEventDestory(start);</span><br><span class="line">cudaEventDestory(stop);</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>创建事件 -&gt; 记录事件的开始 -&gt; 计时部分代码执行 -&gt; 记录事件的结束 -&gt; 计算耗时</p>
<p><strong>GPU计算核心</strong>和<strong>设备内存</strong>之间的数据传输的传输峰值理论带宽要远大于<strong>CPU</strong>与<strong>GPU</strong>之间数据传输的理论峰值带宽，所以，想要获得可观的加速，就必须减少在数据传输上所花的时间，避免过多的数据经过PCIe传递。</p>
<ol start="9">
<li>算数强度</li>
</ol>
<p>一个计算问题的算数强度指的是其中<strong>算数操作</strong>的工作量与<strong>必要的内存操作</strong>的工作量之比</p>
<ol start="10">
<li>一个CUDA程序获得高性能的必要条件：</li>
</ol>
<ul>
<li>数据传输比重小</li>
<li>核函数的算数强度较高</li>
<li>核函数中定义的线程数目较多</li>
</ul>
<p>所以，在优化CUDA程序时尽量做到：</p>
<ul>
<li>减少主机与设备之间的数据传输</li>
<li>提高核函数的算数强度</li>
<li>增大核函数的并行规模</li>
</ul>
<h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><ol>
<li>cudaDeviceRest()</li>
</ol>
<p>用来显式地释放和清空当前进程中与当前设备有关的所有资源。</p>
<ol start="2">
<li>cudaMalloc</li>
</ol>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaMalloc</span><span class="params">(<span class="keyword">void</span>** devPtr, <span class="keyword">size_t</span> size)</span></span>;</span><br></pre></td></tr></table></figure>
<p>同C语言中malloc函数，为变量分配空间。第一个参数为内存分配的对象，第二个是分配的内存空间的<strong>字节</strong>大小。</p>
<ol start="3">
<li>cudaMemcpy</li>
</ol>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaMemcpy</span><span class="params">(<span class="keyword">void</span>* dst, <span class="keyword">const</span> <span class="keyword">void</span>* src, <span class="keyword">size_t</span> count, cudaMemcpuKind kind)</span></span>;</span><br></pre></td></tr></table></figure>
<p>从src指向的内存空间复制一定字节的数据到dst所指内存中，复制方向由kind指定，kind共有以下几种：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cudaMemcpyHostToHost</span><br><span class="line">cudaMemcpyHostToDevice</span><br><span class="line">cudaMemcpyDeviceToHost</span><br><span class="line">cudaMemcpyDeviceToDevice</span><br></pre></td></tr></table></figure></p>
<p>该函数以同步方式执行，在函数返回以及传输操作完成之前主机的应用程序是阻塞的。</p>
<ol start="4">
<li>cudaGetErrorString</li>
</ol>
<p>cudaError_t为枚举类型，此类型变量有两个值：  <strong>cudaSuccess</strong>与<strong>cudaErrorMemoryAllocaion</strong>  </p>
<p>将错误代码转为可读字符串</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">char</span>* <span class="title">cudaGetErrorString</span><span class="params">(cudaError_t error)</span></span>;</span><br></pre></td></tr></table></figure>
<ol start="5">
<li>cudaEventElapsedTime</li>
</ol>
<p>计算事件之间经过(Elapse)的时间<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">host__ cudaError_t <span class="title">cudaEventElapsedTime</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">float</span>* ms,        <span class="comment">//返回事件执行的时间</span></span></span></span><br><span class="line"><span class="function"><span class="params">    cudaEvent_t start, <span class="comment">//事件的开始</span></span></span></span><br><span class="line"><span class="function"><span class="params">    cudaEvent_t end    <span class="comment">//事件的结束</span></span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure></p>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/03/16/UnicodeProgramming/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">&lt;</strong>
      <div class="article-nav-title">
        
          Unicode note
        
      </div>
    </a>
  
  
    <a href="/2020/02/29/MPI/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">MPI学习记录</div>
      <strong class="article-nav-caption">&gt;</strong>
    </a>
  
</nav>

  
</article>


<div class="ds-share share" data-thread-key="CUDA" data-title="CUDA学习记录" data-url="http://yoursite.com/2020/03/15/CUDA/" data-images="/Pictures/timg.ico" data-content="CUDA学习记录">
    <div class="ds-share-inline">
      <ul class="ds-share-icons-16">
      	<li data-toggle="ds-share-icons-more"><a class="ds-more" href="javascript:void(0);">分享到：</a></li>
        <li><a class="ds-weibo" href="javascript:void(0);" data-service="weibo">微博</a></li>
        <li><a class="ds-qzone" href="javascript:void(0);" data-service="qzone">QQ空间</a></li>
        <li><a class="ds-qqt" href="javascript:void(0);" data-service="qqt">腾讯微博</a></li>
        <li><a class="ds-wechat" href="javascript:void(0);" data-service="wechat">微信</a></li>
      </ul>
      <div class="ds-share-icons-more">
      </div>
    </div>
 </div>
 





</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2020 Weizhe Yang
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/smackgg/hexo-theme-smackdown" target="_blank">Smackdown</a>
        </div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="/js/main.js"></script>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js"></script>


  </div>
</body>
</html>
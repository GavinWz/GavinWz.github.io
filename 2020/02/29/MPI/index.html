<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <title>Gavin-MPI学习记录 | Blog</title>

  <!-- keywords -->
  
    <meta name="keywords" content="Gavin">
  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="MPI_Learning_Record环境下载:http://www.mpich.org/downloads/  程序的开始与结束  1int MPI_Init(int *argc, char **argv) 通过MPI_Init函数进入MPI环境并完成初始化工作，标志并行代码的开始, 前后两个参数为main函数的默认参数。1int MPI_Finalize(void) 通过MPI_Finaliz">
<meta name="keywords" content="HPC">
<meta property="og:type" content="article">
<meta property="og:title" content="MPI学习记录">
<meta property="og:url" content="http://yoursite.com/2020/02/29/MPI/index.html">
<meta property="og:site_name" content="Blog">
<meta property="og:description" content="MPI_Learning_Record环境下载:http://www.mpich.org/downloads/  程序的开始与结束  1int MPI_Init(int *argc, char **argv) 通过MPI_Init函数进入MPI环境并完成初始化工作，标志并行代码的开始, 前后两个参数为main函数的默认参数。1int MPI_Finalize(void) 通过MPI_Finaliz">
<meta property="og:locale" content="English & Chinese">
<meta property="og:updated_time" content="2020-09-30T04:43:22.717Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="MPI学习记录">
<meta name="twitter:description" content="MPI_Learning_Record环境下载:http://www.mpich.org/downloads/  程序的开始与结束  1int MPI_Init(int *argc, char **argv) 通过MPI_Init函数进入MPI环境并完成初始化工作，标志并行代码的开始, 前后两个参数为main函数的默认参数。1int MPI_Finalize(void) 通过MPI_Finaliz">
  
    <link rel="alternative" href="/atom.xml" title="Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/Pictures/timg.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  
<script>
    (function(){
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
        }
        else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

  
<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-85415703-1', 'auto');
  ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


  <script src="//cdn.bootcss.com/require.js/2.3.2/require.min.js"></script>
  <script src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script>

  
      <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
<script>AV.initialize("your_app_id", "your_app_key");</script>
<script src="/js/Counter.js"></script>
  
</head></html>
<body>
  <div id="container">
    <div id="particles-js"></div>
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img src="/Pictures/timg.ico" class="js-avatar" style="width: 100%;height: 100%;opacity: 1;">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Weizhe Yang</a></h1>
		</hgroup>

		
		<p class="header-subtitle">Weizhe</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="2">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						<li>友情链接</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/GavinWz/" title="github">github</a>
					        
								<a class="mail" target="_blank" href="/gavinwzmails@gmail.com" title="mail">mail</a>
					        
								<a class="qq" target="_blank" href="#" title="qq">qq</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/HPC/" style="font-size: 20px;">HPC</a> <a href="/tags/hexo/" style="font-size: 10px;">hexo</a> <a href="/tags/学习记录/" style="font-size: 15px;">学习记录</a>
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="https://www.iczc.me/">iczc</a>
			        
			        </div>
				</section>
				

				
				
				<section class="switch-part switch-part4">
				
					<div id="js-aboutme">A student of the College of Computer Engineering of Weifang University. I&#39;m learning hard on Information Technology, and this is where I save my study records.Not all the essays here are my original works, but some of them have helped me a lot in the past time, so I recorded them to share with everyone and it also remind me what should I do if I face the same situations which I have met in the past but forgot how to operate now.</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Weizhe Yang</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="/Pictures/timg.ico" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author">Weizhe Yang</h1>
			</hgroup>
			
			<p class="header-subtitle">Weizhe</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/GavinWz/" title="github">github</a>
			        
						<a class="mail" target="_blank" href="/gavinwzmails@gmail.com" title="mail">mail</a>
			        
						<a class="qq" target="_blank" href="#" title="qq">qq</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-MPI" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2020/02/29/MPI/" class="article-date">
  	<time datetime="2020-02-29T08:03:47.000Z" itemprop="datePublished">2020-02-29</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      MPI学习记录
      
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HPC/">HPC</a></li></ul>
	</div>

        

        
          
<div class="counter-tag counter">
    <span id="/2020/02/29/MPI/" class="leancloud_visitors post-title-link" style="font-size: 12px" data-flag-title="MPI学习记录">
         &nbsp;
        view
    </span>
</div>

        
        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="MPI-Learning-Record"><a href="#MPI-Learning-Record" class="headerlink" title="MPI_Learning_Record"></a>MPI_Learning_Record</h2><p>环境下载:<br><a href="http://www.mpich.org/downloads/" target="_blank" rel="noopener">http://www.mpich.org/downloads/</a></p>
<ol>
<li>程序的开始与结束</li>
</ol>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Init</span><span class="params">(<span class="keyword">int</span> *argc, <span class="keyword">char</span> **argv)</span></span></span><br></pre></td></tr></table></figure>
<p>通过MPI_Init函数进入MPI环境并完成初始化工作，标志并行代码的开始, 前后两个参数为main函数的默认参数。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Finalize</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br></pre></td></tr></table></figure></p>
<p>通过MPI_Finalize函数从MPI环境中推出，标志并行代码的结束，如果不是MPI程序的最后一句则运行结果不可知</p>
<ol start="2">
<li>获取进程的数量：</li>
</ol>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Comm_size</span><span class="params">(MPI_Comm comm, <span class="keyword">int</span> *rank)</span></span></span><br></pre></td></tr></table></figure>
<p>通信子：一组可以相互发送消息的进程集合。通常由MPI_Init()在用户启动程序时， 定义由用户自动的所有进程组成的通信子，缺省值为MPI_COMM_WORLD。<br>这个参数是MPI通信操作函数中必不可少的参数，用户限定参加通信的进程的范围。</p>
<p>参数: 第一个参数是通信子， 第二个参数返回进程的个数</p>
<ol start="3">
<li>获取进程id</li>
</ol>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Comm_rank</span><span class="params">(MPI_Comm comm, <span class="keyword">int</span> *rank)</span></span></span><br></pre></td></tr></table></figure>
<p>获得当前进程在制定通信域中的编号，将自身与其他程序区分。  </p>
<p>第一个参数是通信子，第二个参数返回进程的编号。</p>
<ol start="4">
<li>获取处理器</li>
</ol>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Get_processor_name</span><span class="params">(<span class="keyword">char</span> *name, <span class="keyword">int</span> *resultlen)</span></span></span><br><span class="line"><span class="function"><span class="keyword">char</span> *name</span>;  #返回处理器名</span><br><span class="line"><span class="keyword">int</span> *resultlen;  #在name中返回结果的长度</span><br></pre></td></tr></table></figure>
<ol start="5">
<li><p>运行时间</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">double</span> <span class="title">MPI_Wtime</span><span class="params">(<span class="keyword">void</span>)</span> <span class="comment">//获取时间</span></span></span><br><span class="line"><span class="function"><span class="keyword">double</span> <span class="title">MPI_Wtick</span><span class="params">(<span class="keyword">void</span>)</span> <span class="comment">//查看时间的精度</span></span></span><br></pre></td></tr></table></figure>
</li>
<li><p>同步</p>
</li>
</ol>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Barrier</span><span class="params">(MPI_Comm comm)</span></span></span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line"><span class="number">7.</span> 时间精度</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">```c</span><br><span class="line"><span class="function"><span class="keyword">double</span> <span class="title">MPI_Wtick</span><span class="params">(<span class="keyword">void</span>)</span> <span class="comment">//查看时间的精度</span></span></span><br></pre></td></tr></table></figure>
<ol start="8">
<li>消息传递</li>
</ol>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Send</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span>* msg_buf_p,<span class="comment">//变量指针</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> msg_size, <span class="comment">//数据量</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype send_type, <span class="comment">//发送信息的数据类型</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> dest, <span class="comment">//目标进程的id值</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> tag, <span class="comment">//消息标签，0打印，1计算</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm communicator<span class="comment">//通信子</span></span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Recv</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span>* msg_buf_p, <span class="comment">//变量指针</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> buf_size, <span class="comment">//数据量</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype recv_type, <span class="comment">//发送信息的数据类型；</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> source, <span class="comment">//接收的进程的id值；</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> tag, <span class="comment">//消息标签；0打印，1计算</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm communicator， <span class="comment">//通信子；</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Status *status_p)</span><span class="comment">//status_p对象，包含实际接收到的消息的有关信息</span></span></span><br></pre></td></tr></table></figure>
<p>通常情况下，满足以下条件，就可以成功发送和接收消息：</p>
<pre><code>1. recv_type = send_type
2. recv_buf_size &gt;= send_buf_size
</code></pre><p>接收者的通配参数：</p>
<ul>
<li>MPI_ANY_SOURSE: 当第四个参数source为此变量时，代表任何一个完成工作的进程</li>
<li>MPI_ANY_TAG: 当第五个参数tag为此变量时，代表接收任意形式的标签</li>
</ul>
<p>通配参数只有<code>接收者</code>可以使用</p>
<ol>
<li>地址偏移量</li>
</ol>
<p>MPI_ADDRESS: 获得一个位置在内存中的地址<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Address</span><span class="params">(<span class="keyword">void</span> *location, MPI_Aint *address)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line">void *location: 调用者的内存位置；</span><br><span class="line">MPI_Aint *address: 位置的对应地址</span><br></pre></td></tr></table></figure></p>
<ol start="10">
<li>(规约)集合通信函数</li>
</ol>
<p>涉及通信子中的所有进程的通信函数称为集合通信。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Reduce</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span>* input_data_p,     <span class="comment">//每个线程需要提供的计算数据</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span>* output_data_p,    <span class="comment">//返回计算结果</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> count,              <span class="comment">//每个线程提供的数据量</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype datatype,  <span class="comment">//数据类型</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_OP <span class="keyword">operator</span>,        <span class="comment">//归约操作符</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> dest_process,       <span class="comment">//在指定线程中返回</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure></p>
<p>在指定线程中对通信子中每个线程中的数据进行特定的计算(MPI_OP)，并在该线程中返回计算结果。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Allreduce</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span>* input_data_p,     <span class="comment">//每个线程需要提供的计算数据</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span>* output_data_p,    <span class="comment">//返回计算结果</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> count,              <span class="comment">//每个线程提供的数据量</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype datatype,  <span class="comment">//数据类型</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_OP <span class="keyword">operator</span>,        <span class="comment">//归约操作符</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>
<p>与上面类似，除去dest_process参数。在通信子的所有线程中均返回结果。<br>具体实现：在一个线程中计算出结果后，将结果发布给其他线程。</p>
<p>MPI_OP:</p>
<table>
<thead>
<tr>
<th style="text-align:left">运算符值</th>
<th style="text-align:left">含义</th>
<th style="text-align:center">\</th>
<th style="text-align:left"></th>
<th style="text-align:left">运算符值</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">MPI_MAX</td>
<td style="text-align:left">求最大值</td>
<td style="text-align:center">\</td>
<td style="text-align:left"></td>
<td style="text-align:left">MPI_LOR</td>
<td>逻辑或</td>
</tr>
<tr>
<td style="text-align:left">MPI_MIN</td>
<td style="text-align:left">求最小值</td>
<td style="text-align:center">\</td>
<td style="text-align:left"></td>
<td style="text-align:left">MPI_BOR</td>
<td>按位或</td>
</tr>
<tr>
<td style="text-align:left">MPI_SUM</td>
<td style="text-align:left">求累加和</td>
<td style="text-align:center">\</td>
<td style="text-align:left"></td>
<td style="text-align:left">MPI_LXOR</td>
<td>逻辑异或</td>
</tr>
<tr>
<td style="text-align:left">MPI_PROD</td>
<td style="text-align:left">求累乘积</td>
<td style="text-align:center">\</td>
<td style="text-align:left"></td>
<td style="text-align:left">MPI_BXOR</td>
<td>按位异或</td>
</tr>
<tr>
<td style="text-align:left">MPI_LAND</td>
<td style="text-align:left">逻辑与</td>
<td style="text-align:center">\</td>
<td style="text-align:left"></td>
<td style="text-align:left">MPI_MAXLOC</td>
<td>求最大值和最大值所在位置</td>
</tr>
<tr>
<td style="text-align:left">MPI_BAND</td>
<td style="text-align:left">按位与</td>
<td style="text-align:center">\</td>
<td style="text-align:left"></td>
<td style="text-align:left">MPI_MINLOC</td>
<td>求最小值和最小值所在位置</td>
</tr>
</tbody>
</table>
<ol start="11">
<li>广播<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Bcast</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span>* data_p,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> count,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype datatype,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> source_proc,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>进程号为cource_proc的进程将data_p所引用的内存内容发送给通信子comm中的所有进程</p>
<ol start="12">
<li>散射</li>
</ol>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Scatter</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span>*           send_buf_p, <span class="comment">//需要处理的整体数据</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span>             send_count, <span class="comment">//发送到每个进程的数据量</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype    send_type,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span>*           recv_buf_p, <span class="comment">//本地定义的数组或其他容器用来存储分得的数据</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span>             recv_count, <span class="comment">//每个进程分得的数据量</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype    recv_type,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span>             src_proc,   <span class="comment">//负责读取和分发数据的进程</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm        comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>
<p>若通信子comm包含comm_sz个进程，那么MPI_Scatter函数会将send_buf_p所引用的数据分成comm_sz份，第一份分给0号进程，第二分分给1号进程……以此类推。</p>
<ol start="13">
<li>聚集</li>
</ol>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Gather</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span>*           send_buf_p,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span>             send_count,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype    send_type,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span>*           recv_buf_p,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span>             recv_count,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype    recv_type,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span>             dest_proc,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm        comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>
<p>在指定线程dest_proc中收集当前线程传来的数据，保存在大小为recv_count的recv_type类型数组recv_count中</p>
<ol start="14">
<li>派生数据类型 ???</li>
</ol>
<p>一个派生数据类型是由一系列的MPI基本数据类型和每个数据类型的偏移所组成的</p>
<p>假设一个进程里变量a,b,n和它们在内存中的位置如下</p>
<table>
<thead>
<tr>
<th style="text-align:center">变量</th>
<th style="text-align:center">地址</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">a</td>
<td style="text-align:center">24</td>
</tr>
<tr>
<td style="text-align:center">b</td>
<td style="text-align:center">40</td>
</tr>
<tr>
<td style="text-align:center">n</td>
<td style="text-align:center">48</td>
</tr>
</tbody>
</table>
<p>则可以用以下的派生数据类型表示这些数据项：</p>
<p>{(MPI_DOUBLE,0),(MPI_DOUBLE,16),(MPI_INT,24)}</p>
<p>每组数据的第二个元素是该数据项相对于起始位置的偏移, 即为当前数据与起始数据的内存地址差值。</p>
<p>可以用MPI_Type_creaate_struct函数创建有不同基本数据类型的元素组成的派生数据类型。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Type_create_struct</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> count, <span class="comment">//数据类型中元素的个数</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> array_of_blocklengths[]， <span class="comment">//允许单独的数据项可以是个数组,每个元素表示数组长度</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Aint array_of_displacements[]，<span class="comment">//距离消息起始位置的偏移量,单位为字节</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype array_of_types[],<span class="comment">//数据类型</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype* new_type_p  <span class="comment">//函数建立的新的数据类型</span></span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>
<p>可以使用MPI_Get_address函数来找到制定元素的内存地址<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Get_address</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    voiod* location_p,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Aint* adddress_p</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure></p>
<p>MPI_Aint是个长整数型, address_p返回location_p所指向的内存单元的地址</p>
<p>生成新的数据类型之后需要调用函数MPI_Type_commit去指定它:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Type_commit</span><span class="params">(MPI_Datatype* new_mpi_t_p)</span></span>;</span><br></pre></td></tr></table></figure></p>
<p>调用派生数据类型: 以MPI_Bcast测试:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MPI_Bcast(&amp;a, <span class="number">1</span>, <span class="keyword">input_mpi_t</span>, <span class="number">0</span>, comm);</span><br></pre></td></tr></table></figure></p>
<ol start="15">
<li>数据的打包(Pack)</li>
</ol>
<p>将不连续的数据或是不相同的数据类型的数据一起发送到其它进程</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Pack</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span>* inbuf,  <span class="comment">//待打包的数据</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> incount,  <span class="comment">//打包的数据量</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype datatype, <span class="comment">//数据项的类型</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *outbuf,  <span class="comment">//输入冲区地址</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> outcount,  <span class="comment">//输入缓冲区大小</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> *position, <span class="comment">//缓冲区第一个用于打包的位置</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm, comm <span class="comment">//通信子</span></span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Unpack</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span>* inbuf,             <span class="comment">// 指向待解包缓冲区的指针</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> insize,              <span class="comment">// 缓冲区大小（单位为 Byte）</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span>* position,           <span class="comment">// 输出缓冲区中第一个用于打包的位置（地址偏移量）</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span>* outbuf,            <span class="comment">// 指向解包后数据的指针 </span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> outcount,            <span class="comment">// 解包元素个数    </span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Datatype datatype,   <span class="comment">// 数据类型</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm            <span class="comment">// 通信子</span></span></span></span><br><span class="line"><span class="function"><span class="params"> )</span></span>;</span><br></pre></td></tr></table></figure>
<p>缓冲区的类型任意, 意在分配指定大小的空间足够打包解包时使用, position大小随打包和解包增加和减少</p>
<p>打包完成后可以通过MPI_Send等发送数据的函数将输入缓冲区<strong>outbuf</strong>发送到其他线程,类型为<strong>MPI_PACKED</strong></p>
<p>接收函数MPI_Recv等接收到其他线程发来的包后,需要对其进行解包操作,提取出相应的数据后才能进行下一步操作</p>
<ol start="16">
<li>组的管理</li>
</ol>
<p>组是一个进程的有序集合,在实现中可以看做是进程标识符的一个有序集合,组内的每个进程与一个整数rank相联系,序列号从0开始并且是连续的.我们可以在通信组中使用组来描述通信空间中的参与者并对这些参与者进行分级.</p>
<p>两个特殊的预定义组:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MPI_GROUP_EMPTY: 空组的有效句柄,可以再组操作中作为一个参数使用</span><br><span class="line">MPI_GROUP_NULL: 无效句柄,在组释放时会被返回</span><br></pre></td></tr></table></figure></p>
<ul>
<li><strong>创建</strong><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Comm_group</span><span class="params">(MPI_Comm comm, MPI_Group *group)</span></span>; </span><br><span class="line"><span class="comment">/*建立一个通信组对应的新进程组. group返回组句柄*/</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Group_rank</span><span class="params">(MPI_Group group, <span class="keyword">int</span> *rank)</span></span>; </span><br><span class="line"><span class="comment">/*查询调用进程在进程组里的rank*/</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>说明: MPI不能凭空构造一个组,只能从其他以前定义的组中构造,最基本的组是与初始通信子MPI_COMM_WORLD相联系的组(可通过MPI_COMM_GROUP获得),其他的组均在该组基础上定义.</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Group_incl</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Group old_group,  <span class="comment">//旧进程组</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> count,            <span class="comment">//members数组中元素的个数 </span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> *members,         <span class="comment">//旧进程组中需要放入新进程组进程的编号</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Group *new_group  <span class="comment">//新进程组</span></span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>
<p>基于已经存在的进程组创建一个新的进程组,并指明被包含(include)的成员进程</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Group_excl</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Group old_group, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> count,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> *nonmembers,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Group *new_group</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>
<p>基于已经存在的进程创建一个新的进程组,并指明不被包含(exclude)的成员进程, 即新进程组包含除nonmembers之外的其它进程</p>
<ul>
<li><strong>比较</strong></li>
</ul>
<p>对两个进程组判断其成员是否相同,次序是否一致.</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Group_compare</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Group group1, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Group group2,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> *result</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span></span><br></pre></td></tr></table></figure>
<p>如果两个组中成员和次序完全相等,则返回<strong>MPI_IDENT</strong><br>如果组成员相同但次序不同,则返回<strong>MPI_SIMILAR</strong><br>其它情况返回<strong>MPI_UNEQUAL</strong></p>
<ul>
<li><strong>相对编号</strong><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Group_translate_ranks</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Group group1, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> count,   <span class="comment">//进程组1中有效编号的个数</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> *ranks1, <span class="comment">//进程组1中有效编号组成的数组</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Group group2,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> *ranks2  <span class="comment">//ranks1中的元素在进程组2中的对应编号</span></span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>检测两个不同组中相同进程的相对编号,如果属于进程组1的某个进程的编号在ranks1中,但此进程不属于进程组2,则在ranks2中对应ranks1的位置返回值为MPI_UNDEFINED;若此进程属于进程组2,则在ranks2中对应ranks1的位置返回此进程在进程组2中的编号</p>
<ul>
<li><p><strong>集合类操作</strong></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Group_union</span><span class="params">( <span class="comment">//进程组的集合并操作</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Group group1,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Group group2,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Group *newgroup</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Group_intersection</span><span class="params">( <span class="comment">//进程组的集合交操作</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Group group1, </span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Group group2,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Group *newgroup</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Group_defference</span><span class="params">(  <span class="comment">//newgroup=group2-group1</span></span></span></span><br><span class="line"><span class="function"><span class="params"><span class="comment">/*进程组的集合补操作, 返回group1在group2中的相对补集*/</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Group group1,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Group group2,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Group *newgroup</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>释放</strong></p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int MPI_Group_free(MPI_Group *group);</span><br></pre></td></tr></table></figure>
<p>释放指定进程组,组句柄被置为MPI_GROUP_NULL  </p>
<p>函数允许任何正在使用此组的操作正常完成</p>
<ol start="17">
<li>通信子的管理</li>
</ol>
<ul>
<li><p><strong>复制</strong></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Comm_dup</span><span class="params">(MPI_Comm comm, MPI_Comm *newcomm)</span></span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>创建</strong></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Comm_creeate</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm,   <span class="comment">//旧通信子</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Group group, <span class="comment">//与comm相关联的组或其子集</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm *new_comm <span class="comment">//新通信子</span></span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>用由group所定义的通信组及一个新的上下文创建了一个新的通信自new_comm,对于不在group中的进程,函数返回MPI_COMM_NULL,所以新的通信子中包含group中的进程</p>
<ul>
<li><strong>划分</strong><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Comm_split</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm comm, <span class="comment">//旧的通信子,即被划分的域</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> color,  <span class="comment">//子域的标识,被划分出来的每个子域都对应一个color,每个子域包含具有同样color的所有进程</span></span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> key, <span class="comment">//每个子域内,进程按照key所定义的值的次序进行排列</span></span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Comm *new_comm</span></span></span><br><span class="line"><span class="function"><span class="params">)</span></span>;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>函数将与comm相关的域划分为若干不相连的子域,根据color和key参数决定每个进程所处的位置</p>
<ul>
<li><strong>释放</strong><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Comm_free</span><span class="params">(MPI_Comm *comm)</span></span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>将指定通信子的句柄置为MPI_COMM_NULL,任何使用此通信子的挂起操作都会正常完成;仅当没有对此对象的活动引用时,它才会被实际撤销</p>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/03/15/CUDA/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">&lt;</strong>
      <div class="article-nav-title">
        
          CUDA学习记录
        
      </div>
    </a>
  
  
    <a href="/2020/02/10/OpenMP/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">OpenMP学习记录</div>
      <strong class="article-nav-caption">&gt;</strong>
    </a>
  
</nav>

  
</article>


<div class="ds-share share" data-thread-key="MPI" data-title="MPI学习记录" data-url="http://yoursite.com/2020/02/29/MPI/" data-images="/Pictures/timg.ico" data-content="MPI学习记录">
    <div class="ds-share-inline">
      <ul class="ds-share-icons-16">
      	<li data-toggle="ds-share-icons-more"><a class="ds-more" href="javascript:void(0);">分享到：</a></li>
        <li><a class="ds-weibo" href="javascript:void(0);" data-service="weibo">微博</a></li>
        <li><a class="ds-qzone" href="javascript:void(0);" data-service="qzone">QQ空间</a></li>
        <li><a class="ds-qqt" href="javascript:void(0);" data-service="qqt">腾讯微博</a></li>
        <li><a class="ds-wechat" href="javascript:void(0);" data-service="wechat">微信</a></li>
      </ul>
      <div class="ds-share-icons-more">
      </div>
    </div>
 </div>
 





</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
      <div class="footer-left">
        &copy; 2020 Weizhe Yang
      </div>
        <div class="footer-right">
          <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/smackgg/hexo-theme-smackdown" target="_blank">Smackdown</a>
        </div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: false,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="/js/main.js"></script>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js"></script>


  </div>
</body>
</html>